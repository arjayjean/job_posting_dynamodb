{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a1acdc6",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9482e231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in /opt/anaconda3/lib/python3.9/site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.9/site-packages (from google-search-results) (2.30.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.9/site-packages (from requests->google-search-results) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests->google-search-results) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests->google-search-results) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests->google-search-results) (2022.9.24)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8bf4431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/anaconda3/lib/python3.9/site-packages (1.24.28)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.28 in /opt/anaconda3/lib/python3.9/site-packages (from boto3) (1.27.28)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/anaconda3/lib/python3.9/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/anaconda3/lib/python3.9/site-packages (from boto3) (0.6.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/anaconda3/lib/python3.9/site-packages (from botocore<1.28.0,>=1.27.28->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/anaconda3/lib/python3.9/site-packages (from botocore<1.28.0,>=1.27.28->boto3) (1.26.11)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.28->boto3) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d65a8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import GoogleSearch\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bcb1204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search_metadata': {'id': '6453fc46382427c4f7429868',\n",
       "  'status': 'Success',\n",
       "  'json_endpoint': 'https://serpapi.com/searches/c6ba9a7c911b6273/6453fc46382427c4f7429868.json',\n",
       "  'created_at': '2023-05-04 18:41:10 UTC',\n",
       "  'processed_at': '2023-05-04 18:41:10 UTC',\n",
       "  'google_jobs_url': 'https://www.google.com/search?q=data+engineer&ibp=htl;jobs&uule=w+CAIQICINVW5pdGVkIFN0YXRlcw&hl=en&gl=us',\n",
       "  'raw_html_file': 'https://serpapi.com/searches/c6ba9a7c911b6273/6453fc46382427c4f7429868.html',\n",
       "  'total_time_taken': 2.52},\n",
       " 'search_parameters': {'q': 'data engineer',\n",
       "  'engine': 'google_jobs',\n",
       "  'location_requested': 'United States',\n",
       "  'location_used': 'United States',\n",
       "  'google_domain': 'google.com',\n",
       "  'hl': 'en',\n",
       "  'gl': 'us'},\n",
       " 'jobs_results': [{'title': 'Big Data Engineer, Mid',\n",
       "   'company_name': 'Booz Allen Hamilton',\n",
       "   'location': '  Norfolk, VA   ',\n",
       "   'via': 'via Booz Allen Hamilton',\n",
       "   'description': 'Big Data Engineer, Mid\\n\\nThe Opportunity...\\n\\nDo you want to work at the forefront of advanced technology and solve complex data challenges? You know that data yields pivotal insights when it’s gathered from disparate sources and organized. As a data engineer, you have the chance to develop and deploy the pipelines and platforms that make this data meaningful. What’s more, you’ll have the chance to help grow Booz Allen’s DataOps capabilities while working with a multi-disciplinary team of analysts, data engineers, data scientists, developers, and data consumers in a fast-paced, agile environment. We’re looking for someone like you to work with our clients and meet their mission by working with a multi-disciplinary team of analysts, data engineers, data scientists, developers, machine learning engineers, and data consumers in a fast-paced agile environment.\\n\\nThis is an opportunity to implement data engineering activities on some of the most mission-driven projects in the industry. Supporting a multitude of clients across numerous domains, you’ll have the chance to architect data systems, stand up data platforms, build out ETL pipelines, develop custom tooling, interface with data stores, and manage data life cycle operations. From sharing your skills in analytical exploration and examination of data to supporting the assessment, design, building, and maintenance of scalable platforms, you’ll work with our clients to solve their most pressing challenges.\\n\\nReady to help drive innovation using cutting-edge data tools and techniques?\\n\\nJoin us. The world can’t wait.\\n\\nYou Have:\\n• 3+ years of experience in a professional work environment\\n• 3+ years of experience with designing, developing, operationalizing, and maintaining complex data applications at an enterprise scale\\n• 3+ years of experience with creating data solutions in SQL or scripting languages to retrieve, parse, and process structured and unstructured data\\n• 3+ years of experience with building scalable Extract Transform Load (ETL) processes for reporting and analytics\\n• Experience with management consulting techniques, including client interviews, data gathering, and problem-solving\\n• Experience with using Microsoft Excel and Access\\n• Ability to develop scripts and programs for converting types of data into usable formats and support project team to scale, monitor and operate data platforms\\n• Ability to obtain a security clearance\\n• Bachelor’s degree\\n\\nNice If You Have:\\n• Experience with GitHub or version control systems\\n• Experience with UNIX/Linux, including basic commands and Shell scripting\\n• Experience with Microsoft Visual Basic for Applications (VBA)\\n• Experience with a public cloud, including AWS, Microsoft Azure, or Google Cloud\\n• Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka\\n• Experience with NoSQL implementation, including MongoDB or Cassandra\\n• Experience with data warehousing using AWS Redshift, MySQL, or Snowflake\\n• Experience with Agile engineering practices and working on real-time data and streaming applications\\n• Experience with data visualization tools, including Tableau, QlikSense, or Microsoft Power BI\\n• Bachelor’s degree in Economics, Operations Research, Management Science, Mathematics, or Statistics\\n\\n\\u200b\\n\\nClearance:\\n\\n\\u200b\\u200bApplicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.\\n\\nCreate Your Career:\\n\\nAt Booz Allen, we know the power of analytics and we’re dedicated to helping you grow as a data analysis professional. When you join Booz Allen, you’ll have the chance to:\\n• access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\\n• change the world with the Data Science Bowl—the world’s premier data science for social good competition\\n• participate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government\\n\\nYou’ll have access to a wealth of training resources through our Analytics University, an online learning portal specifically geared towards data science and analytics skills, where you can access more than 5000 functional and technical courses, certifications, and books. Build your technical skills through hands-on training on the latest tools and state-of-the-art tech from our in-house experts. Pursuing certifications that directly impact your role? You may be able to take advantage of our tuition assistance, on-site bootcamps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips. We’ll help you develop the career you want as you chart your own course for success.\\n\\nCompensation\\n\\nAt Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.\\n\\nSalary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,300.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.\\n\\nWork Model\\nOur people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.\\n• If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.\\n• If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.\\n\\nEEO Commitment\\n\\nWe’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law',\n",
       "   'job_highlights': [{'title': 'Qualifications',\n",
       "     'items': ['3+ years of experience in a professional work environment',\n",
       "      '3+ years of experience with designing, developing, operationalizing, and maintaining complex data applications at an enterprise scale',\n",
       "      '3+ years of experience with creating data solutions in SQL or scripting languages to retrieve, parse, and process structured and unstructured data',\n",
       "      '3+ years of experience with building scalable Extract Transform Load (ETL) processes for reporting and analytics',\n",
       "      'Experience with management consulting techniques, including client interviews, data gathering, and problem-solving',\n",
       "      'Experience with using Microsoft Excel and Access',\n",
       "      'Ability to develop scripts and programs for converting types of data into usable formats and support project team to scale, monitor and operate data platforms',\n",
       "      'Ability to obtain a security clearance',\n",
       "      'Experience with GitHub or version control systems',\n",
       "      'Experience with UNIX/Linux, including basic commands and Shell scripting',\n",
       "      'Experience with Microsoft Visual Basic for Applications (VBA)',\n",
       "      'Experience with a public cloud, including AWS, Microsoft Azure, or Google Cloud',\n",
       "      'Experience with distributed data and computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka',\n",
       "      'Experience with NoSQL implementation, including MongoDB or Cassandra',\n",
       "      'Experience with data warehousing using AWS Redshift, MySQL, or Snowflake',\n",
       "      'Experience with Agile engineering practices and working on real-time data and streaming applications',\n",
       "      'Experience with data visualization tools, including Tableau, QlikSense, or Microsoft Power BI',\n",
       "      'Bachelor’s degree in Economics, Operations Research, Management Science, Mathematics, or Statistics']},\n",
       "    {'title': 'Responsibilities',\n",
       "     'items': ['As a data engineer, you have the chance to develop and deploy the pipelines and platforms that make this data meaningful',\n",
       "      'This is an opportunity to implement data engineering activities on some of the most mission-driven projects in the industry',\n",
       "      'Supporting a multitude of clients across numerous domains, you’ll have the chance to architect data systems, stand up data platforms, build out ETL pipelines, develop custom tooling, interface with data stores, and manage data life cycle operations',\n",
       "      'From sharing your skills in analytical exploration and examination of data to supporting the assessment, design, building, and maintenance of scalable platforms, you’ll work with our clients to solve their most pressing challenges',\n",
       "      'If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role']},\n",
       "    {'title': 'Benefits',\n",
       "     'items': ['You may be able to take advantage of our tuition assistance, on-site bootcamps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips',\n",
       "      'At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being',\n",
       "      'Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care',\n",
       "      'The projected compensation range for this position is $58,300.00 to $133,000.00 (annualized USD)']}],\n",
       "   'related_links': [{'link': 'http://www.boozallen.com/',\n",
       "     'text': 'boozallen.com'},\n",
       "    {'link': 'https://www.google.com/search?gl=us&hl=en&q=Booz+Allen+Hamilton&sa=X&ved=0ahUKEwjPrdmhqNz-AhX_mWoFHZ20DhAQmJACCNAJ',\n",
       "     'text': 'See web results for Booz Allen Hamilton'}],\n",
       "   'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSOiIU_YS9mKYqtUeG89nq3qvNdm-CPDSuRD1m1EAM&s',\n",
       "   'extensions': ['2 days ago', 'Full-time', 'Health insurance'],\n",
       "   'detected_extensions': {'posted_at': '2 days ago',\n",
       "    'schedule_type': 'Full-time'},\n",
       "   'job_id': 'eyJqb2JfdGl0bGUiOiJCaWcgRGF0YSBFbmdpbmVlciwgTWlkIiwiaHRpZG9jaWQiOiJSOE05MVNJMU95MEFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJTlZXNXBkR1ZrSUZOMFlYUmxjdyIsImdsIjoidXMiLCJobCI6ImVuIiwiZmMiOiJFb3dDQ3N3QlFVVnpOMnBPVW5SUVZUWXdkVXB4T0RVNGNHUXpTbkpyTFRKUk1HRldSMnR5VWtKSVZFeFZWV0ppVm1zeFNHMUdTbVJPV0hVNWR6VktTVjl2ZGtoalF6bDNjVWRsWkVOdVdrOUJPVUozU1hkZmQyOTNUa3BrWVVwTFNVNXFja1UxY2s1alVuSTFTWGxWTkRSVVNVSnNlV2hVWTFnNWRETm9ha3BzU1ZwT2RYaFBjV2xWYTBwWGNIWmhUVU5RYldwMFUxWklhM2xKUjJWM1JrNTZNRk5DV0daU04yUlBUREpRWXpSNFYzbGxUbXRaZHpkSmNXVmlhMmRYVGtNM2RVMWpOR3hDYWxaeVpVcERObEE1RWhkU1gzaFVXa2xmZFVSZkxYcHhkSE5RYm1WdE5tZEJSUm9pUVU4dE1ISnNOalJ1TFhwclFrRjViRWQ2WXpZeVJuVjFla2x6ZFZadmIyUlZRUSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzEiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiLm5GZzJlYntmb250LXdlaWdodDo1MDB9LkJpNkRkY3tmb250LXdlaWdodDo1MDB9QXBwbHkgb24gQm9veiBBbGxlbiBIYW1pbHRvbiIsImxpbmsiOiJodHRwczovL2NhcmVlcnMuYm9vemFsbGVuLmNvbS90ZWFtcy9Kb2JEZXRhaWwvTm9yZm9say1CaWctRGF0YS1FbmdpbmVlci1NaWQtUjAxNzA2NzUvNzg4MzI/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=='},\n",
       "  {'title': 'Sr. Big Data Engineer (Hybrid)',\n",
       "   'company_name': 'S&P Global',\n",
       "   'location': '  New York, NY   ',\n",
       "   'via': 'via EFinancialCareers',\n",
       "   'description': \"Sr. Big Data Engineer (Hybrid)\\n\\nS&P Global Ratings...\\n\\nJob Title: Sr. Big Data Engineer\\n\\nLocation: NY, New York\\n\\nThe Grade : 12\\n\\nJob Description:\\nS&P Global Ratings is looking for an experienced Big Data Engineer to join Data Engineering team within Chief Data Office, a team of data and technology professionals who define and execute the strategic data roadmap for S&P Global Ratings. The successful candidate will participate in the design and build of S&P Ratings cloud based analytics platform to help develop and deploy advanced analytics/machine learning solutions.\\n\\nResponsibilities:\\n• Design and develop efficient and scalable data pipelines between enterprise systems and analytics platform\\n• Work closely with Data Science team and participate in development of feature engineering pipelines\\n• Provide technical expertise in the areas of design and implementation of Ratings Integrated Data Facility with modern AWS cloud technologies such as S3, Redshift, EMR, Hive, Presto and Spark\\n• Build and maintain a data environment for speed, accuracy, consistency and 'up' time\\n• Support analytics by building a world-class data lake environment that empowers analysts to determine insights into revenue and power products across the organization\\n• Work with the machine learning engineering team to build a data eco system that supports AI products at scale\\n• Ensure data governance principles adopted, data quality checks and data lineage implemented in each hop of the data\\n• Partner with the chief data office, enterprise architecture organization to ensure best use of standards for the key data domains and use cases\\n• Be in tune with emerging trends Big data and cloud technologies and participate in evaluation of new technologies\\n• Ensure compliance through the adoption of enterprise standards and promotion of best practice / guiding principles aligned with organization standards\\n\\nExperience & Qualifications:\\n• BS or MS degree in Computer Science or Information Technology\\n• 8+ years of experience as data engineer at an innovative organization\\n• 4+ years of hands-on experience in implementing data lake systems using AWS cloud technologies such as S3, Redshift, EMR, Hive, Presto and Spark\\n• Expert managing AWS services (EC2, S3, Route 53, ELB, VPC, cloudwatch, Lambda) in a multi account production environment\\n• Experience With Machine Learning Libraries and Frameworks (TensorFlow , MLlib) is an added advantage\\n• Exposure to R , SparklyR , and Other R packages is a Plus\\n• Experience with development frameworks as well as data and integration technologies such as Informatica, Python, Scala\\n• Expert knowledge of Agile approaches to software development and able to put key Agile principles into practice to deliver solutions incrementally.\\n• Monitors industry trends and directions; develops and presents substantive technical recommendations to senior management\\n• Excellent analytical thinking, interpersonal, oral and written communication skills with strong ability to influence both IT and business partners\\n• Ability to prioritize and manage work to critical project timelines in a fast-paced environment\\n• Financial services industry experience The Team\\nYou will be an expert contributor and part of the Rating Organization's Data Services Team. This team, who has a broad and expert knowledge on Ratings organization's critical data domains, technology stacks and architectural patterns, fosters knowledge sharing and collaboration that results in a unified strategy. All Data Services team members provide leadership, innovation, timely delivery, and the ability to articulate business value. Be a part of a unique opportunity to build and evolve S&P Ratings next gen analytics platform.\\n\\nOur Hiring Manager Says\\nIf you are an individual that brings demonstrated experience of delivering big data projects as a data engineer, this is an excellent opportunity. I am looking for someone with sound technical knowledge, can be hands-on, worked on transformational initiatives, and can drive results.\\n\\nCompensation and Benefits Information:\\nS&P Global states that the anticipated base salary range for this position is $82,600 - $230,200. Base salary ranges may vary by geographic location.\\n\\nIn addition to base compensation, this role is eligible for an annual incentive bonus.\\n\\nThis role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit\\nhttps://www.spgbenefitessentials.com/newhires\\n\\nS&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment.\\n\\nIf you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.\\n\\nThe EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. -----------------------------------------------------------\\n\\nEqual Opportunity Employer\\nS&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment.\\n\\nIf you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.\\n\\nUS Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law.\\n\\n-----------------------------------------------------------\\n\\n20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.2 - Middle Professional Tier II (EEO Job Group), SWP Priority - Ratings - (Strategic Workforce Planning)\\n\\nJob ID: 276199\\nPosted On: 2023-04-17\\nLocation: New York, New York, United States\",\n",
       "   'job_highlights': [{'title': 'Qualifications',\n",
       "     'items': ['BS or MS degree in Computer Science or Information Technology',\n",
       "      '8+ years of experience as data engineer at an innovative organization',\n",
       "      '4+ years of hands-on experience in implementing data lake systems using AWS cloud technologies such as S3, Redshift, EMR, Hive, Presto and Spark',\n",
       "      'Expert managing AWS services (EC2, S3, Route 53, ELB, VPC, cloudwatch, Lambda) in a multi account production environment',\n",
       "      'Experience With Machine Learning Libraries and Frameworks (TensorFlow , MLlib) is an added advantage',\n",
       "      'Experience with development frameworks as well as data and integration technologies such as Informatica, Python, Scala',\n",
       "      'Expert knowledge of Agile approaches to software development and able to put key Agile principles into practice to deliver solutions incrementally',\n",
       "      'Monitors industry trends and directions; develops and presents substantive technical recommendations to senior management',\n",
       "      'Excellent analytical thinking, interpersonal, oral and written communication skills with strong ability to influence both IT and business partners',\n",
       "      'Ability to prioritize and manage work to critical project timelines in a fast-paced environment',\n",
       "      'Financial services industry experience The Team',\n",
       "      'I am looking for someone with sound technical knowledge, can be hands-on, worked on transformational initiatives, and can drive results']},\n",
       "    {'title': 'Responsibilities',\n",
       "     'items': ['The successful candidate will participate in the design and build of S&P Ratings cloud based analytics platform to help develop and deploy advanced analytics/machine learning solutions',\n",
       "      'Design and develop efficient and scalable data pipelines between enterprise systems and analytics platform',\n",
       "      'Work closely with Data Science team and participate in development of feature engineering pipelines',\n",
       "      'Provide technical expertise in the areas of design and implementation of Ratings Integrated Data Facility with modern AWS cloud technologies such as S3, Redshift, EMR, Hive, Presto and Spark',\n",
       "      \"Build and maintain a data environment for speed, accuracy, consistency and 'up' time\",\n",
       "      'Support analytics by building a world-class data lake environment that empowers analysts to determine insights into revenue and power products across the organization',\n",
       "      'Work with the machine learning engineering team to build a data eco system that supports AI products at scale',\n",
       "      'Ensure data governance principles adopted, data quality checks and data lineage implemented in each hop of the data',\n",
       "      'Partner with the chief data office, enterprise architecture organization to ensure best use of standards for the key data domains and use cases',\n",
       "      'Be in tune with emerging trends Big data and cloud technologies and participate in evaluation of new technologies',\n",
       "      'Ensure compliance through the adoption of enterprise standards and promotion of best practice / guiding principles aligned with organization standards']},\n",
       "    {'title': 'Benefits',\n",
       "     'items': ['S&P Global states that the anticipated base salary range for this position is $82,600 - $230,200',\n",
       "      'Base salary ranges may vary by geographic location',\n",
       "      'In addition to base compensation, this role is eligible for an annual incentive bonus',\n",
       "      'This role is eligible to receive additional S&P Global benefits']}],\n",
       "   'related_links': [{'link': 'https://www.spglobal.com/',\n",
       "     'text': 'spglobal.com'},\n",
       "    {'link': 'https://www.google.com/search?gl=us&hl=en&q=S%26P+Global&sa=X&ved=0ahUKEwjPrdmhqNz-AhX_mWoFHZ20DhAQmJACCJUK',\n",
       "     'text': 'See web results for S&P Global'}],\n",
       "   'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR6MP3Ltq8jjT_aGCCcJGxlddAj-GAMTuWALNb5e1g&s',\n",
       "   'extensions': ['9 hours ago', 'Full-time', 'Health insurance'],\n",
       "   'detected_extensions': {'posted_at': '9 hours ago',\n",
       "    'schedule_type': 'Full-time'},\n",
       "   'job_id': 'eyJqb2JfdGl0bGUiOiJTci4gQmlnIERhdGEgRW5naW5lZXIgKEh5YnJpZCkiLCJodGlkb2NpZCI6InBLdlBNR0kyc1N3QUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lOVlc1cGRHVmtJRk4wWVhSbGN3IiwiZ2wiOiJ1cyIsImhsIjoiZW4iLCJmYyI6IkVvd0NDc3dCUVVWek4ycE9VMU5oYTNRdGVqZFdXR3RFTW05WFpDMVZRVVJmTTFnM1NXSXpOblF4YW5OMmVGZGFNMGhKTUdrNGVWSjJhVGxYVldGWk1XeHZTWFo0T0VWWGFHWkRURzR4YVVzNFJHVnBVMjF0YmpBemNGZEJlV2cxUnkxWU1VRXhZazA1Y2s5SVdtdDJSVWhZTVc5bFRWTnlaVGhIVHpSaGFsZEJPWE5CUldOWFRWUkpTSGhWUkZCU2JERnJRVlZIWVY5TU1YVmtPRmhFWW5wMWRHWnVaMjkxVERBdGRqbFlaVk5ZV1Y5VldHMVRTMjQwT1hFeGVtUlVTVFpPVmtoamRqaEpkVXRHVEZsck5qSjVFaGRTWDNoVVdrbGZkVVJmTFhweGRITlFibVZ0Tm1kQlJSb2lRVTh0TUhKc05HdGpXVmMwVG01cmJYaFpNRTFMVUVsbU9GbFJXSEkzYjBaNVVRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMyIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBFRmluYW5jaWFsQ2FyZWVycyIsImxpbmsiOiJodHRwczovL3d3dy5lZmluYW5jaWFsY2FyZWVycy5jb20vam9icy1VU0EtTlktTmV3X1lvcmstU3JfQmlnX0RhdGFfRW5naW5lZXJfSHlicmlkLmlkMTk1MjA1MTA/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=='},\n",
       "  {'title': 'Data Engineer',\n",
       "   'company_name': 'Millennium',\n",
       "   'location': '  New York, NY   ',\n",
       "   'via': 'via LinkedIn',\n",
       "   'description': 'We are looking for a Data Engineer that will architect and implement systems handling the ingestion, cleaning, and structuring of data. They will be a member of the Data Science team and will have direct interaction with the people using the data ingested. The hire will also be responsible for managing our group’s core infrastructure including our region redundant pipeline orchestration servers... (Airflow) and webserver stack (NGINX + Gunicorn + Django). The ideal candidate is an experienced data pipeline builder and core infrastructure guru.\\n\\nResponsibilities\\n• Create and maintain an optimal data pipelines in Python + SQL\\n• Build and maintain the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Python and SQL (Snowflake & SQL Server) in both on premise and cloud environments\\n• Manage and improve the user facing server infrastructure (web + api) including authorization and load balancing\\n• Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\\n• Build analytics tools that that provide actionable insights on both the user interactions and infrastructure loads\\n\\nTechnical Qualifications\\n• Python expert, notably savvy with data science stack (Pandas, NumPy, SciPy)\\n• Relational SQL databases, Microsoft SQL Server and Postgres preferred\\n• Snowflake cloud database experience\\n• Pipeline and workflow management tools: Airflow, Luigi, etc.\\n• Experience with AWS cloud services: EC2, EMR, RDS, Redshift, Athena, SQS, etc.\\n• 2+ professional years’ experience with Masters or 3+ professional years with Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.\\n\\nHighly Valued\\n• Data Science/Analysis background\\n• Computer science understanding, data structures, processes, threading, memory usage\\n• Unix/Linux command-line experience\\n• Broad understanding of equities, derivatives, futures, FX, or other financial-services instruments\\n\\nOther Qualifications\\n• Excellent listening, and communication (both oral and written) skills\\n• Self-starter and critical thinker, takes ownership of own projects and makes improvement suggestions for the entire infrastructure.\\n• Proactive, assertive and attentive to details.\\n• Can work independently and in a collaborative environment.\\n• Can handle several projects with different priorities at the same time in a fast-paced environment.\\n• Excellent self-management and problem-solving skills.\\n• Results-oriented, can deliver quality code quickly\\n\\nMillennium pays a total compensation package which includes a base salary, discretionary performance bonus, and a comprehensive benefits package. The estimated base salary range for this position is $150,000, which is specific to New York and may change in the future. When finalizing an offer, we take into consideration an individual’s experience level and the qualifications they bring to the role to formulate a competitive total compensation package',\n",
       "   'job_highlights': [{'title': 'Qualifications',\n",
       "     'items': ['Python expert, notably savvy with data science stack (Pandas, NumPy, SciPy)',\n",
       "      'Snowflake cloud database experience',\n",
       "      'Pipeline and workflow management tools: Airflow, Luigi, etc',\n",
       "      'Experience with AWS cloud services: EC2, EMR, RDS, Redshift, Athena, SQS, etc',\n",
       "      '2+ professional years’ experience with Masters or 3+ professional years with Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field',\n",
       "      'Highly Valued',\n",
       "      'Data Science/Analysis background',\n",
       "      'Computer science understanding, data structures, processes, threading, memory usage',\n",
       "      'Unix/Linux command-line experience',\n",
       "      'Broad understanding of equities, derivatives, futures, FX, or other financial-services instruments',\n",
       "      'Excellent listening, and communication (both oral and written) skills',\n",
       "      'Self-starter and critical thinker, takes ownership of own projects and makes improvement suggestions for the entire infrastructure',\n",
       "      'Proactive, assertive and attentive to details',\n",
       "      'Can work independently and in a collaborative environment',\n",
       "      'Can handle several projects with different priorities at the same time in a fast-paced environment',\n",
       "      'Excellent self-management and problem-solving skills',\n",
       "      'Results-oriented, can deliver quality code quickly']},\n",
       "    {'title': 'Responsibilities',\n",
       "     'items': ['We are looking for a Data Engineer that will architect and implement systems handling the ingestion, cleaning, and structuring of data',\n",
       "      'They will be a member of the Data Science team and will have direct interaction with the people using the data ingested',\n",
       "      'The hire will also be responsible for managing our group’s core infrastructure including our region redundant pipeline orchestration servers (Airflow) and webserver stack (NGINX + Gunicorn + Django)',\n",
       "      'Create and maintain an optimal data pipelines in Python + SQL',\n",
       "      'Build and maintain the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Python and SQL (Snowflake & SQL Server) in both on premise and cloud environments',\n",
       "      'Manage and improve the user facing server infrastructure (web + api) including authorization and load balancing',\n",
       "      'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc',\n",
       "      'Build analytics tools that that provide actionable insights on both the user interactions and infrastructure loads']},\n",
       "    {'title': 'Benefits',\n",
       "     'items': ['Millennium pays a total compensation package which includes a base salary, discretionary performance bonus, and a comprehensive benefits package',\n",
       "      'The estimated base salary range for this position is $150,000, which is specific to New York and may change in the future',\n",
       "      'When finalizing an offer, we take into consideration an individual’s experience level and the qualifications they bring to the role to formulate a competitive total compensation package']}],\n",
       "   'related_links': [{'link': 'http://www.millenniumbcp.pt/',\n",
       "     'text': 'millenniumbcp.pt'},\n",
       "    {'link': 'https://www.google.com/search?gl=us&hl=en&q=Millennium&sa=X&ved=0ahUKEwjPrdmhqNz-AhX_mWoFHZ20DhAQmJACCNoK',\n",
       "     'text': 'See web results for Millennium'}],\n",
       "   'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTA0E9r5KG7uiRZhdaOrRmvsYRz6vtad437FvbpWJk&s',\n",
       "   'extensions': ['1 day ago', 'Full-time', 'Health insurance'],\n",
       "   'detected_extensions': {'posted_at': '1 day ago',\n",
       "    'schedule_type': 'Full-time'},\n",
       "   'job_id': 'eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiIyc184LU83SU5fVUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJTlZXNXBkR1ZrSUZOMFlYUmxjdyIsImdsIjoidXMiLCJobCI6ImVuIiwiZmMiOiJFdmNCQ3JjQlFVVnpOMnBPVkROMVVITnRSMjg1VG5BMVUxSjJVVTV3YkRST2QwdGxObGd3U0hCbFNUTlhkM1JrYTBkSVZUbExjVGxzV2tOc1JWTndabmh6TW1kUVJrOUpRa2g0VTJkeVZURlpkR3d3YUVSTFJYcE1XbEJLWW1zelUxbzNkRlYzWkVVMFZGOXBXbXQ2ZURkQ0xXcHdNM0owZWs1blEwSm1VR1JmWkVaR2VXVlRjRzV1ZVdWQ2JEUnZTMVZ4T1VkR2VFNUpkbk5YTkdOUlduaFNNamhqWTJNNWVuZHlSWHBWWVZjeVNEbGFWRlkzUWtKR2FIQXdFaGRTWDNoVVdrbGZkVVJmTFhweGRITlFibVZ0Tm1kQlJSb2lRVTh0TUhKc05sb3hPUzEyWmxkbmRuaG1ZV3RpVGtoMVUzSjJiWFpJUkZwbVFRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfNSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBMaW5rZWRJbiIsImxpbmsiOiJodHRwczovL3d3dy5saW5rZWRpbi5jb20vam9icy92aWV3L2RhdGEtZW5naW5lZXItYXQtbWlsbGVubml1bS0zNTkxNTgxMDEzP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0='},\n",
       "  {'title': 'Data Engineer//Atlanta, GA (Local)// FullTime',\n",
       "   'company_name': 'Pacific Consulting',\n",
       "   'location': ' Anywhere ',\n",
       "   'via': 'via LinkedIn',\n",
       "   'description': 'Job Description:\\n• At least 9 years of Programming experience\\n• Strong Python development experience with Python, Pandas , NumPy, Pyspark...\\n• Strong knowledge on AWS services such as (S3, RDS, EC2, Lambda, SQS, SNS, Redshift)\\n• Having prior working experience in Fannie Mae will be added advantage\\n• Good Knowledge on Java and Database (Oracle Postgres',\n",
       "   'job_highlights': [{'title': 'Qualifications',\n",
       "     'items': ['At least 9 years of Programming experience',\n",
       "      'Strong Python development experience with Python, Pandas , NumPy, Pyspark',\n",
       "      'Strong knowledge on AWS services such as (S3, RDS, EC2, Lambda, SQS, SNS, Redshift)',\n",
       "      'Having prior working experience in Fannie Mae will be added advantage',\n",
       "      'Good Knowledge on Java and Database (Oracle Postgres)']}],\n",
       "   'related_links': [{'link': 'https://www.google.com/search?gl=us&hl=en&q=Pacific+Consulting&sa=X&ved=0ahUKEwjPrdmhqNz-AhX_mWoFHZ20DhAQmJACCJcL',\n",
       "     'text': 'See web results for Pacific Consulting'}],\n",
       "   'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTB0l4bu1X5Oc7ZtnJRMrVFQLGNvwdP_OMVzJ3QXJ8&s',\n",
       "   'extensions': ['1 day ago',\n",
       "    'Work from home',\n",
       "    'Full-time',\n",
       "    'No degree mentioned'],\n",
       "   'detected_extensions': {'posted_at': '1 day ago',\n",
       "    'schedule_type': 'Full-time',\n",
       "    'work_from_home': True},\n",
       "   'job_id': 'eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyLy9BdGxhbnRhLCBHQSAoTG9jYWwpLy8gRnVsbFRpbWUiLCJodGlkb2NpZCI6Ik9LRHZQQUhmM3VRQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lOVlc1cGRHVmtJRk4wWVhSbGN3IiwiZ2wiOiJ1cyIsImhsIjoiZW4iLCJmYyI6IkVxSUNDdUlCUVVWek4ycE9VMng2Ym5GVlMxUjBOM2h5VDB4SUxXZFBVR3RsYkZCbWRIZHBhak0wYUMxbFVtZFVOUzFZWmpReVMydDNZV2g2YkVoM1kzVlZialpDUjE5SVYyVXRTa3BvVVU1dmJWVXhjbTU2Tm5aalgwNWtWMjVSVGpNd1RVUmtURmhaTWtaM1VsWnFlWGhtUW5VMldVZFJhMEpqYlRWRWQzaDFYME54V1d4Q2JWRkdhemhUYVhZNVRDMVdZVTlHYlhwelNGUmplRWRPZUVOQ1kxQklMVVkwWmpRMWNUVXljVWhNWmt0NlpHbEJTbVZoV0dzMWVtWmFhak01YUdsVWVITm9aR2cyV1hGRlJsWnNhMHhTWWtNd1dXTkZhbXR6YzIxS2NrWlBaSGhNWnhJWFVsOTRWRnBKWDNWRVh5MTZjWFJ6VUc1bGJUWm5RVVVhSWtGUExUQnliRFprWlMxaloxcGFkMjlyVFRRemEyUTBWWFJCTWt4QlZIcFRWMUUiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY183IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIExpbmtlZEluIiwibGluayI6Imh0dHBzOi8vd3d3LmxpbmtlZGluLmNvbS9qb2JzL3ZpZXcvZGF0YS1lbmdpbmVlci1hdGxhbnRhLWdhLWxvY2FsLWZ1bGx0aW1lLWF0LXBhY2lmaWMtY29uc3VsdGluZy0zNTk0OTEzNjkyP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0='},\n",
       "  {'title': 'Data Engineer',\n",
       "   'company_name': 'Barclays',\n",
       "   'location': '  Florham Park, NJ   ',\n",
       "   'via': 'via EFinancialCareers',\n",
       "   'description': \"As a Barclays Data Engineer, you will be contributing directly to the execution of the business strategy and play a key role in development of future state data science platform. Investment Banking Analytics works in close partnership with our product and coverage businesses to design, develop and deliver valuable data and analytic content. We are accountable for the continued development and... evolution of the analytic capabilities to support the growing reliance on data and creating model driven outcomes.\\n\\nBarclays is one of the world's largest and most respected financial institutions, with 329 years of success, quality, and innovation behind us. We've helped millions of individuals and businesses thrive, creating financial and digital solutions that the world now takes for granted. An important and growing presence in the USA, we offer careers providing endless opportunity.\\n\\nWorking Flexibly\\n\\nWe're committed to providing a supportive and inclusive culture and environment for you to work in. This environment recognises and supports ways to balance your personal needs, alongside the professional needs of our business. Providing the opportunity for all our employees, globally to work flexibly empowers each of us to work in a way that suits our lives as well as enabling us to better service our customers' and clients' needs. Whether you have family commitments or you're a carer, or whether you need study time or wish to pursue personal interests, our approach to working flexibly is designed to help you balance your life.\\n\\nIf you would like some flexibility, then please discuss this with the hiring manager, and your request will be reviewed subject to business needs.\\n\\nWe are currently in the early stages of implementing a hybrid working environment, which means that many colleagues spend part of their working hours at home and part in the office, depending on the nature of the role they are in. We're flexible on how this works and it may continue to change and evolve. Depending on your team, typically this means that colleagues spend a minimum of between 20% to 60% of their time in the office, which could be over a week, a month, or a quarter. However, some colleagues may choose to spend more time in the office over a typical period than their role type requires. We also have a flexible working process where, subject to business needs, all colleagues globally can request work patterns to reflect their personal circumstances.\\n\\nPlease discuss the detail of the working pattern options for the role with the hiring manager.\\n\\nWhat you will be doing?\\n\\n• Designing scalable and secure engineering solutions that will be leveraged by Banking colleagues and customers\\n• Working closely with a cross-functional team of data scientists and database developers, business Intelligence designers, architects, business analysts and infrastructure engineers\\n• Developing and designing of new data science platform with Python and AWS based applications and components\\n• Coordinating as a team player in a global development group participating in requirements and data analysis, design as well as development\\n• Communicating and collaborating between the infrastructure, development, and business groups\\n• Operating in a dynamic environment that demands multi-tasking.\\n• Generating ideas and efficiently mockup proposals and demos\\n\\nWhat we're looking for\\n\\n• B.S. degree in computer science or related field with emphasis on technology\\n• Five plus years of experience in Python\\n• Two plus years AWS experience\\n• Significant years of SQL experience\\n\\nSkills that will help you in the role\\n\\n• Significant Experience and understanding with AWS Services such as Lambda, Glue, Athena, ECS, Cloud Formation\\n• Excellent Experience in developing REST APIs using Python and understanding of web architectures\\n• Understanding of SQL, Kubernetes, ECS, Docker Swarm, OpenShift as well as working in working in UNIX environment including knowledge of shell scripts\\n• Experience and understanding of relational database techniques, data warehouse concepts\\n\\nWhere will you be working?\\n\\nAt Barclays, we are proud to be redefining the future of finance and here at Whippany we are defining the future of the workplace and the future of the way we work and live. We are creating a unique community, one of four strategic tech-enabled hubs that will redefine opportunity for everyone who works here. Whatever you do at Whippany, you'll have every chance to build a world-class career in this world-class environment.\\n\\n#data\",\n",
       "   'job_highlights': [{'title': 'Qualifications',\n",
       "     'items': ['B.S. degree in computer science or related field with emphasis on technology',\n",
       "      'Five plus years of experience in Python',\n",
       "      'Two plus years AWS experience',\n",
       "      'Significant years of SQL experience',\n",
       "      'Significant Experience and understanding with AWS Services such as Lambda, Glue, Athena, ECS, Cloud Formation',\n",
       "      'Excellent Experience in developing REST APIs using Python and understanding of web architectures',\n",
       "      'Understanding of SQL, Kubernetes, ECS, Docker Swarm, OpenShift as well as working in working in UNIX environment including knowledge of shell scripts',\n",
       "      'Experience and understanding of relational database techniques, data warehouse concepts']},\n",
       "    {'title': 'Responsibilities',\n",
       "     'items': ['As a Barclays Data Engineer, you will be contributing directly to the execution of the business strategy and play a key role in development of future state data science platform',\n",
       "      'Depending on your team, typically this means that colleagues spend a minimum of between 20% to 60% of their time in the office, which could be over a week, a month, or a quarter',\n",
       "      'Designing scalable and secure engineering solutions that will be leveraged by Banking colleagues and customers',\n",
       "      'Working closely with a cross-functional team of data scientists and database developers, business Intelligence designers, architects, business analysts and infrastructure engineers',\n",
       "      'Developing and designing of new data science platform with Python and AWS based applications and components',\n",
       "      'Coordinating as a team player in a global development group participating in requirements and data analysis, design as well as development',\n",
       "      'Communicating and collaborating between the infrastructure, development, and business groups',\n",
       "      'Operating in a dynamic environment that demands multi-tasking',\n",
       "      'Generating ideas and efficiently mockup proposals and demos']}],\n",
       "   'related_links': [{'link': 'https://www.barclays.com/',\n",
       "     'text': 'barclays.com'},\n",
       "    {'link': 'https://www.google.com/search?gl=us&hl=en&q=Barclays&sa=X&ved=0ahUKEwjPrdmhqNz-AhX_mWoFHZ20DhAQmJACCN0L',\n",
       "     'text': 'See web results for Barclays'}],\n",
       "   'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRVuSS6Uhm_vB6FHVlwCpO4e_D7IKsxdSOgiCLbw4A&s',\n",
       "   'extensions': ['8 days ago', 'Full-time'],\n",
       "   'detected_extensions': {'posted_at': '8 days ago',\n",
       "    'schedule_type': 'Full-time'},\n",
       "   'job_id': 'eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiJUOGg4a2pOUHRGd0FBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJTlZXNXBkR1ZrSUZOMFlYUmxjdyIsImdsIjoidXMiLCJobCI6ImVuIiwiZmMiOiJFdmNCQ3JjQlFVVnpOMnBPVkdSQ1pXSlNMVTVUWTNoTk1GSkhjSFo1U3pKNGJFSnpaRXM1TmpsalRqSnJWRlpRUjJRME1uZFJZek5XVlZGQ2VEaHhTbFoyWlZORGNtMVNjalJUZW5vMGFVUTJTV293YUdGcU5HOUhaV0ZrYVdOR0xUQldTMkZsWm1KTFVrWnVVRVJaVldFMFZDMXZTRzAyZW1zNFMzQkNXWHBsUkZZMk9FdHdVVVpSVEZrNE5GOW5aWE4zT1ZCamVsbEliMmw0VERaWlpWRndhM0kwVUhSQk5HNWlhelZIYVRoWVQyRjRlV1puTkRWU2N6bFZFaGRTWDNoVVdrbGZkVVJmTFhweGRITlFibVZ0Tm1kQlJSb2lRVTh0TUhKc04xbGliMGN3TUdaMkxUSjNPSEkzUVVsRllqRkJSSFZRU2xOcWR3IiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfOSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBFRmluYW5jaWFsQ2FyZWVycyIsImxpbmsiOiJodHRwczovL3d3dy5lZmluYW5jaWFsY2FyZWVycy5jb20vam9icy1VU0EtTkotRmxvcmhhbV9QYXJrLURhdGFfRW5naW5lZXIuaWQxOTQ1NDg4OT91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19'},\n",
       "  {'title': 'Data Engineer',\n",
       "   'company_name': 'DeleteMe',\n",
       "   'location': '  United States   ',\n",
       "   'via': 'via Startup Jobs',\n",
       "   'description': \"The Data Engineer will help us manage and use data to make good decisions about what we build, how we help our customers, and how we grow our company. The ideal candidate will work closely with our engineering and product teams to improve the way we collect, structure, and store data, and with our management, marketing, sales, and service teams to understand what they need to know about the business and get them the data they need to help them make good decisions. We are building our data practice from the ground up so you will have the opportunity to work on a new modern date engineering tech stack. We use Snowflake as our Data Warehouse and Fivetran as our ETL tool. We use dbt to model our data and enable CI/CD capabilities. We are big Open Source users and use Apache Superset as our reporting tool. Reverse ETL is performed using Hightouch and components of Rudderstack. Our broader engineering stack includes AWS, Terraform, Docker, and Kubernetes. We are just getting started though... so you will be a key driver of building our data engineering practice from the ground up. Job Responsibilities: Analyze the data we have and the data we create to better understand its value. Improve our data collection and storage practices to enhance the value of our internal dataBuild pipelines and data flows to ensure our data is available where it is needed when it is neededInterview business users and document reporting requirements, develop ELT, data models and dashboards to fulfill requirements.Design and implement a strategy and systems for data reporting, querying, and visualization to enable everyone in the business to explore our data, answer their questions, and make good decisions. Job Requirements: You don’t need a specific background for this role. We’re looking for someone with some experience in data engineering, data warehousing, data analysis, data modeling and reporting, who wants to be a big part of helping a team achieve big things, who believes in privacy as a mission, and who can both operate independently and help a team be more than the sum of its parts. These are some of the specific characteristics we are looking for.Strong technical and people skillsExcellent written and verbal communication skillsExperience with data engineering/data warehousing/analytics engineeringExperience with building SQL based data pipelines and data modelsExperience with database design and implementationExperience with gathering and document reporting requirementsExperience with data reporting and visualization toolsExperience with appropriate programming languages and technologiesPreferred experience with existing toolset: Fivetran, Snowflake, DBT, Superset and HightouchA Bachelor's or more advanced degree is great, but not required computer Science or other STEM degree is great, but not required ability to thrive in a fast-paced work environment, where change is a constant, and flexibility is key. What We Offer:Comprehensive health benefits flexible schedule100% work from homogeneous 401k matchingPaid time off12 company paid holidaysGym membership reimbursementBirthday time off child care expense reimbursementAbine provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training\",\n",
       "   'job_highlights': [{'items': [\"The Data Engineer will help us manage and use data to make good decisions about what we build, how we help our customers, and how we grow our company. The ideal candidate will work closely with our engineering and product teams to improve the way we collect, structure, and store data, and with our management, marketing, sales, and service teams to understand what they need to know about the business and get them the data they need to help them make good decisions. We are building our data practice from the ground up so you will have the opportunity to work on a new modern date engineering tech stack. We use Snowflake as our Data Warehouse and Fivetran as our ETL tool. We use dbt to model our data and enable CI/CD capabilities. We are big Open Source users and use Apache Superset as our reporting tool. Reverse ETL is performed using Hightouch and components of Rudderstack. Our broader engineering stack includes AWS, Terraform, Docker, and Kubernetes. We are just getting started though... so you will be a key driver of building our data engineering practice from the ground up. Job Responsibilities: Analyze the data we have and the data we create to better understand its value. Improve our data collection and storage practices to enhance the value of our internal dataBuild pipelines and data flows to ensure our data is available where it is needed when it is neededInterview business users and document reporting requirements, develop ELT, data models and dashboards to fulfill requirements.Design and implement a strategy and systems for data reporting, querying, and visualization to enable everyone in the business to explore our data, answer their questions, and make good decisions. Job Requirements: You don’t need a specific background for this role. We’re looking for someone with some experience in data engineering, data warehousing, data analysis, data modeling and reporting, who wants to be a big part of helping a team achieve big things, who believes in privacy as a mission, and who can both operate independently and help a team be more than the sum of its parts. These are some of the specific characteristics we are looking for.Strong technical and people skillsExcellent written and verbal communication skillsExperience with data engineering/data warehousing/analytics engineeringExperience with building SQL based data pipelines and data modelsExperience with database design and implementationExperience with gathering and document reporting requirementsExperience with data reporting and visualization toolsExperience with appropriate programming languages and technologiesPreferred experience with existing toolset: Fivetran, Snowflake, DBT, Superset and HightouchA Bachelor's or more advanced degree is great, but not required computer Science or other STEM degree is great, but not required ability to thrive in a fast-paced work environment, where change is a constant, and flexibility is key. What We Offer:Comprehensive health benefits flexible schedule100% work from homogeneous 401k matchingPaid time off12 company paid holidaysGym membership reimbursementBirthday time off child care expense reimbursementAbine provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training\"]}],\n",
       "   'related_links': [{'link': 'https://www.google.com/search?gl=us&hl=en&q=DeleteMe&sa=X&ved=0ahUKEwjPrdmhqNz-AhX_mWoFHZ20DhAQmJACCIoM',\n",
       "     'text': 'See web results for DeleteMe'}],\n",
       "   'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRTVvDi7e-c_Wz8LMpf1Q-kAtlptZi81k8kGpT4lnQ&s',\n",
       "   'extensions': ['18 hours ago', 'Full-time', 'Paid time off'],\n",
       "   'detected_extensions': {'posted_at': '18 hours ago',\n",
       "    'schedule_type': 'Full-time'},\n",
       "   'job_id': 'eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiJ0bmFEWmEyejJrNEFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJTlZXNXBkR1ZrSUZOMFlYUmxjdyIsImdsIjoidXMiLCJobCI6ImVuIiwiZmMiOiJFc3dCQ293QlFVVnpOMnBPVTNOaFZWWk5USEF6V0VkS2NqQkNXV016Vm01Q2VtVmZSMk0zUWpkd1V6RnBTVmxxZFY5WFVsbFhWekJZWVdWNmFGSTJTR0V6TVV0NGNESnJSbkkyV0dweFMyd3lRbG81V1RoS1lUTjFaVWxxV0ZCa1RHUkJaVzFaVVZZMmRraGlhMXB0VkdkUk9HbEZZekZvYUU5TFNHRjVTMHRwYzJNMllUVjNjSFJsVm5veFNVOXVSV29TRjFKZmVGUmFTVjkxUkY4dGVuRjBjMUJ1WlcwMlowRkZHaUpCVHkwd2NtdzJWVzVGZUhkT1dIVnBkREpKUm00NWRXUXdkMUZUZUMxUGMyaG4iLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xMSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBTdGFydHVwIEpvYnMiLCJsaW5rIjoiaHR0cHM6Ly9zdGFydHVwLmpvYnMvZGF0YS1lbmdpbmVlci1kZWxldGVtZS00Mzk0MjUwP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0='},\n",
       "  {'title': 'Data Engineer 1',\n",
       "   'company_name': 'Saxon Global Inc',\n",
       "   'location': '  Aurora, IL   ',\n",
       "   'via': 'via ZipRecruiter',\n",
       "   'description': \"The main function of a data engineer is to ensure that the data assets of an organization are supported by an architecture that supports the organization in achieving its strategic goal. A typical data engineer is responsible for setting enterprise standards for databases, data integration, and the means to get to the data.\\n\\nJob Responsibilities...\\nTest programs or databases, correct errors and make necessary modifications.\\n\\nModify existing databases and database management systems or direct programmers and analysts to make changes.\\n\\nWrite and code logical and physical database descriptions and specify identifiers of database to management system or direct others in coding descriptions.\\n\\nSkills:\\nVerbal and written communication skills, problem solving skills, customer service and interpersonal skills.\\nBasic ability to work independently and manage ones time.\\nBasic knowledge of logical data modeling and physical data modeling.\\nBasic knowledge of computer software, such as SQL, Visual Basic, Oracle, etc.\\n\\nEducation/Experience:\\nAssociate's degree in computer programming or a relevant field required. Bachelor's degree preferred.\\n0-2 years experience required.\\n\\nRequired Skills : Snowflake and python\\nBasic Qualification :\\nAdditional Skills :\\nBackground Check :Yes\\nDrug Screen :Yes\\nNotes :\\nSelling points for candidate :\\nProject Verification Info :\\nCandidate must be your W2 Employee :Yes\\nExclusive to Apex :No\\nFace to face interview required :No\\nCandidate must be local :No\\nCandidate must be authorized to work without sponsorship :Yes\\nInterview times set : :No\\nType of project :Other Project Type\\nMaster Job Title :Misc: Non-Technical\\nBranch Code :Bloomington\",\n",
       "   'job_highlights': [{'title': 'Qualifications',\n",
       "     'items': ['Verbal and written communication skills, problem solving skills, customer service and interpersonal skills',\n",
       "      'Basic ability to work independently and manage ones time',\n",
       "      'Basic knowledge of logical data modeling and physical data modeling',\n",
       "      'Basic knowledge of computer software, such as SQL, Visual Basic, Oracle, etc',\n",
       "      \"Associate's degree in computer programming or a relevant field required\",\n",
       "      '0-2 years experience required',\n",
       "      'Required Skills : Snowflake and python',\n",
       "      'Background Check :Yes',\n",
       "      'Drug Screen :Yes',\n",
       "      'Candidate must be authorized to work without sponsorship :Yes']},\n",
       "    {'title': 'Responsibilities',\n",
       "     'items': ['A typical data engineer is responsible for setting enterprise standards for databases, data integration, and the means to get to the data',\n",
       "      'Test programs or databases, correct errors and make necessary modifications',\n",
       "      'Modify existing databases and database management systems or direct programmers and analysts to make changes',\n",
       "      'Write and code logical and physical database descriptions and specify identifiers of database to management system or direct others in coding descriptions']}],\n",
       "   'related_links': [{'link': 'http://www.saxonglobal.com/',\n",
       "     'text': 'saxonglobal.com'},\n",
       "    {'link': 'https://www.google.com/search?gl=us&hl=en&q=Saxon+Global+Inc&sa=X&ved=0ahUKEwjPrdmhqNz-AhX_mWoFHZ20DhAQmJACCMwM',\n",
       "     'text': 'See web results for Saxon Global Inc'}],\n",
       "   'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR_Xt7YlRL6bI3D0oKNQhqQYu3zZfMTY6nGGeIB&s=0',\n",
       "   'extensions': ['2 days ago', 'Full-time'],\n",
       "   'detected_extensions': {'posted_at': '2 days ago',\n",
       "    'schedule_type': 'Full-time'},\n",
       "   'job_id': 'eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIDEiLCJodGlkb2NpZCI6InlLVGRvamhsNUJVQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lOVlc1cGRHVmtJRk4wWVhSbGN3IiwiZ2wiOiJ1cyIsImhsIjoiZW4iLCJmYyI6IkV2Y0JDcmNCUVVWek4ycE9VVzh0TTNaRkxWOWZkbWRUYkVoa1ExbHhRbFYwV0VVMWFEZHJSR3BPTVhKeFYyeFNZWGxoVVdKVGFraFNTakJtUms1TFVUUm5abnAyWVhGSlMySkdiVEJrVFhSMlNGRlJjVFY2ZEU1Vk5FRk1SMmRWYlRoRVUwbG9ha1l5YjJwMWQxcHhibkJQU0RrM2VtcE5jRzEwWmtWRlUxTlVPSFkwWjBkdk9VTm9WRXhyUjJSMmIyZEJlRTFFZEVkNlRuSk9UMlpGVlVGcFYwSmZjV0UxWVhSRWVsZGtjMk5mWlhaZmVXcDZiVUV5WlRGUkVoZFNYM2hVV2tsZmRVUmZMWHB4ZEhOUWJtVnRObWRCUlJvaVFVOHRNSEpzTkVoUE5uSktYMnhwTm1RNFVGODRSa1pmUVRGaGRUVldSVTQxZHciLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xMiIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBkaXJlY3RseSBvbiBaaXBSZWNydWl0ZXIiLCJsaW5rIjoiaHR0cHM6Ly93d3cuemlwcmVjcnVpdGVyLmNvbS9jL1NheG9uLUdsb2JhbC1JbmMvSm9iL0RhdGEtRW5naW5lZXItMS8taW4tQXVyb3JhLElMP2ppZD0zM2Q3ZmVlNjMxYTM2NDM0XHUwMDI2dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=='},\n",
       "  {'title': 'Data Engineer',\n",
       "   'company_name': 'S&P Global',\n",
       "   'location': '  New York, NY   ',\n",
       "   'via': 'via Career Center',\n",
       "   'description': \"The Role: - Data Engineer - Engineer II\\nLocation: US remote or hybrid; CST/EST preferred\\nGL : 9 (for internal use only...\\n\\nAs a member of the Data Operations team, you will help modernize the extensive data domain of the Issuer Solutions business. As we redesign and reimagine our client-facing and internal tools, data quality and consistency across multiple tools and platforms will be a key factor in our success, and the DataOps team is tasked with ensuring that all data consumers, from developers to business analysts to clients, have tools to access the data they need in the format they need it.\\n\\nResponsibilities:\\n• Designing and implementing data-ingestion and data-publishing tools for diverse datasets.\\n• Implementing and maintaining data-monitoring and data-cataloguing tools.\\n• Implementing and maintaining process-management and data-movement tools for ETL's.\\n• Offering guidance and best practices to scrum teams who work with data.\\n• Evaluating and implementing new data management technology with the goal of continually improving team efficiency and data quality.\\n• Providing support and guidance for business analysts using data analysis tools such as Alteryx and PowerBI.\\nWhat We're Looking For:\\n• Minimum of 3+ years experience as a software engineer\\n• Experience as a Data Engineer in a production environment\\n• Focus on ETL's, data monitoring, data engineering, etc.\\n• Python, C#, Docker, MS SQL Server, PostgreSQL\\n• Experience with AWS and/or Azure DevOps\\n• AWS tech: Aurora DB, Glue, Lambda\\n• Alteryx Server\\n• Infrastructure as code using Terraform/CloudFormation\\n• Solid understanding of containers and orchestration tools (Docker, CI/CD, etc.)\\n• AirFlow, DataHub, NiFi and other data-management and process-management tools a plus\\n• Experience with BI and analytical tools such as PowerBI and Alteryx\\nCompensation/Benefits Information:\\nS&P Global states that the anticipated base salary range for this position is $58,300 to $115,000 . Base salary ranges may vary by geographic location.\\nThis role is eligible to receive S&P Global benefits. For more information on the benefits we provide to our employees, visit S&P Benefits\\n\\nAbout S&P Global Market Intelligence :\\nAt S&P Global Market Intelligence, we know that not all information is important-some of it is vital. Accurate, deep and insightful. We integrate financial and industry data, research and news into tools that help track performance, generate alpha, identify investment ideas, understand competitive and industry dynamics, perform valuation and assess credit risk. Investment professionals, government agencies, corporations and universities globally can gain the intelligence essential to making business and financial decisions with conviction.\\nS&P Global Market Intelligence is a division of S&P Global (NYSE: SPGI), which provides essential intelligence for individuals, companies and governments to make decisions with confidence. For more information, visit www.spglobal.com/marketintelligence\\n\\n-----------------------------------------------------------\\n\\nEqual Opportunity Employer\\nS&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment.\\n\\nIf you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.\\n\\nUS Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law.\\n\\n-----------------------------------------------------------\\n\\n20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.1 - Middle Professional Tier I (EEO Job Group), SWP Priority - Ratings - (Strategic Workforce Planning)\\n\\nJob ID: R29171\\nPosted On: 2023-02-07\\nLocation: Virtual, North Carolina, United States\",\n",
       "   'job_highlights': [{'title': 'Qualifications',\n",
       "     'items': ['Minimum of 3+ years experience as a software engineer',\n",
       "      'Experience as a Data Engineer in a production environment',\n",
       "      \"Focus on ETL's, data monitoring, data engineering, etc\",\n",
       "      'Python, C#, Docker, MS SQL Server, PostgreSQL',\n",
       "      'Experience with AWS and/or Azure DevOps',\n",
       "      'Infrastructure as code using Terraform/CloudFormation',\n",
       "      'Solid understanding of containers and orchestration tools (Docker, CI/CD, etc.)',\n",
       "      'Experience with BI and analytical tools such as PowerBI and Alteryx',\n",
       "      'We integrate financial and industry data, research and news into tools that help track performance, generate alpha, identify investment ideas, understand competitive and industry dynamics, perform valuation and assess credit risk']},\n",
       "    {'title': 'Responsibilities',\n",
       "     'items': ['As a member of the Data Operations team, you will help modernize the extensive data domain of the Issuer Solutions business',\n",
       "      'As we redesign and reimagine our client-facing and internal tools, data quality and consistency across multiple tools and platforms will be a key factor in our success, and the DataOps team is tasked with ensuring that all data consumers, from developers to business analysts to clients, have tools to access the data they need in the format they need it',\n",
       "      'Designing and implementing data-ingestion and data-publishing tools for diverse datasets',\n",
       "      'Implementing and maintaining data-monitoring and data-cataloguing tools',\n",
       "      \"Implementing and maintaining process-management and data-movement tools for ETL's\",\n",
       "      'Offering guidance and best practices to scrum teams who work with data',\n",
       "      'Evaluating and implementing new data management technology with the goal of continually improving team efficiency and data quality',\n",
       "      'Providing support and guidance for business analysts using data analysis tools such as Alteryx and PowerBI']},\n",
       "    {'title': 'Benefits',\n",
       "     'items': ['S&P Global states that the anticipated base salary range for this position is $58,300 to $115,000',\n",
       "      'Base salary ranges may vary by geographic location',\n",
       "      'This role is eligible to receive S&P Global benefits',\n",
       "      'For more information on the benefits we provide to our employees, visit S&P Benefits']}],\n",
       "   'related_links': [{'link': 'https://www.spglobal.com/',\n",
       "     'text': 'spglobal.com'},\n",
       "    {'link': 'https://www.google.com/search?gl=us&hl=en&q=S%26P+Global&sa=X&ved=0ahUKEwjPrdmhqNz-AhX_mWoFHZ20DhAQmJACCJEN',\n",
       "     'text': 'See web results for S&P Global'}],\n",
       "   'extensions': ['1 day ago',\n",
       "    'Full-time',\n",
       "    'No degree mentioned',\n",
       "    'Health insurance'],\n",
       "   'detected_extensions': {'posted_at': '1 day ago',\n",
       "    'schedule_type': 'Full-time'},\n",
       "   'job_id': 'eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiJfQUlubWZVWElzVUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJTlZXNXBkR1ZrSUZOMFlYUmxjdyIsImdsIjoidXMiLCJobCI6ImVuIiwiZmMiOiJFdmNCQ3JjQlFVVnpOMnBPVkRKVUxVVnBVMmRqUmpOQmRrOVdhRTA0VTFCcmNHVkJTRjh3TkdGQ1VWWlhkVEp3ZVhkeFVGWmZiMkZFY0Y5eFdrdHdabFZ0VUU1clQzQkxNa0ZvZFdWalYwUlZNa0ZEY0ZodGJXTTJWSFJPUjFoUFRWZDZWbE10YzNCU1pGWjNlblIyYkhOalYzSnBNR1p4VVVGSWRtczBkVmw0ZG1sMlRERTVZMkZtY0hOcVkxTm1SMDVJYm5aVFIwWnNVM1ZmUmxGaFNFOWxSbmRZWm5Sa2NWUjFZbWg0VUZBMWNXcE5WalV5UTBReE1sZFpFaGRTWDNoVVdrbGZkVVJmTFhweGRITlFibVZ0Tm1kQlJSb2lRVTh0TUhKc05uazBaekV6Wm1KRWQxRldWSE5rWkRWaU1IUlRWVXh2ZDNweVVRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTQiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gQ2FyZWVyIENlbnRlciIsImxpbmsiOiJodHRwczovL2NhcmVlcnMuam91cm5hbGlzdHMub3JnL2pvYnMvMTg1MzUxMzYvZGF0YS1lbmdpbmVlcj91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19'},\n",
       "  {'title': 'Data Engineer',\n",
       "   'company_name': 'Pitchbook',\n",
       "   'location': '  Seattle, WA   ',\n",
       "   'via': 'via Careers At PitchBook Data - PitchBook',\n",
       "   'description': \"At PitchBook, we are always looking forward. We continue to innovate, evolve and invest in ourselves to bring out the best in everyone. We’re deeply collaborative and thrive on the excitement, energy and fun that reverberates throughout the company.\\n\\nOur extensive mentorship, education and training programs help us create a culture of curiosity that pushes us to always find new solutions and... better ways of doing things. The combination of a rapidly evolving industry and our high ambitions means there’s going to be some ambiguity along the way, but we excel when we challenge ourselves. We’re willing to take risks, fail fast and do it all over again in the pursuit of excellence.\\n\\nIf you have a good attitude and are willing to roll up your sleeves to get things done, PitchBook is the place for you.\\n\\nAbout the Role:\\n\\nThe PitchBook Business Intelligence team embraces this data-driven ethos by delivering key analytics and insights internally to every facet of our business. Our work is manifested as tools and data to help the enterprise grow and run more efficiently at both strategic and tactical levels. Simply put, we believe that the data we build is our competitive advantage for making the most of our resources while we bring the most compelling product possible to market.\\n\\nTo that end, as our scope of data integration and analysis expands so do the needs of the Business Intelligence team. We’re looking for a person with the ability to work with a range of data and reporting technologies (eg. Python, Docker, Tableau, Power BI) in order to build upon a strong foundation of rigor, quantitative techniques and efficient processing. The Data Engineer will join other Engineers and Analytics professionals as part of the team that develops data pipelines and insights for our internal stakeholders across Sales, Customer Success, Marketing, Research, Product, Finance and Administration.\\n\\nPrimary Job Responsibilities:\\n• You’ll be PitchBook’s expert at building unified data tech to support advanced and automated business analytics\\n• Design, develop, document and maintain database and reporting structures used to compile insights\\n• Define, develop and review extract, transform and load processes and data modeling solutions\\n• Consistently evolve data processes and techniques in accordance with industry best practices\\n• Establish and help define reports and dashboards used to translate business data into insights, identify and prioritize operational improvement opportunities and measure business performance against objectives\\n• Contribute to the ongoing improvement of quality assurance standards and procedures\\n\\nSkills and Qualifications:\\n• Bachelor's degree in Economics, Business, Finance, Engineering, Statistics, Computer Science or related fields\\n• 2 years of relevant work experience creating and maintaining data pipelines and architecture\\n• Understanding of advanced data warehousing concepts, data modeling and extract, transform and load development\\n• Advanced SQL skills with experience querying large datasets from multiple sources and developing automated reporting\\n• Python skills for scripting, data manipulation, custom extract, transform and loads and statistical/regression analysis particularly, as they apply to sales and marketing operations and performance\\n• Experience with software programs, such as Tableau, Microsoft Power BI, Docker, Linux and Postgres\\n• Ability to display complex quantitative data in a simple, intuitive format and to present findings in a clear and concise manner\\n• Capable of investigating, familiarizing and mastering new data sets quickly\\n• Excellent interpersonal skills, with the ability to communicate complex data issues correctly and clearly to both internal and external customers\\n• Experience with presenting actionable insights to business stakeholders\\n• Experience with: Airflow, Luigi, Amazon Web Services, Microsoft Azure, Git, Postgres, Debezium and Kafka is preferred\\n• Experience with Snowflake development and cloud data warehousing is preferred\\n\\nBenefits + Compensation at PitchBook:\\n\\nPhysical Health\\n• Comprehensive health benefits\\n• Additional medical wellness incentives\\n• STD, LTD, AD&D and life insurance\\n\\nEmotional Health\\n• Paid sabbatical program after four years\\n• Paid family and paternity leave\\n• Annual educational stipend\\n• Ability to apply for tuition reimbursement\\n• CFA exam stipend\\n• Robust training programs on industry and soft skills\\n• Employee assistance program\\n• Generous allotment of vacation days, sick days and volunteer days\\n\\nSocial Health\\n• Matching gifts program\\n• Employee resource groups\\n• Subsidized emergency childcare\\n• Dependent Care FSA\\n• Company-wide events\\n• Employee referral bonus program\\n• Quarterly team building events\\n\\nFinancial Health\\n• 401k match\\n• Shared ownership employee stock program\\n• Monthly transportation stipend\\n• Please be aware the above PitchBook benefit and perk offerings are subject to corresponding plan and policy documents and may change during the course of your employment.\\n\\nCompensation\\n• Annual base salary: $96,600-$164,450\\n• Target annual bonus percentage: 10%\\n• Starting pay will be based on several factors and commensurate with qualifications & experience. We also have a location-based compensation structure; there may be different ranges for candidates by location.\\n\\nLife At PB:\\n\\nWe are consistently recognized as a Best Place to Work and our culture is at the heart of our success. It’s our fundamental belief that people do and create great things and that people are the cornerstone of prosperity. We believe that proactively seeking out different points of view, listening to others, learning and reflecting on what we’ve heard creates a sense of belonging within PitchBook and strengthens the PitchBook community.\\n\\nWe are excited to get to know you and your background. Concerned that you might not meet every requirement? We encourage you to still apply as you might be the right candidate for the role or other roles at PitchBook.\\n\\n#LI-BL1\",\n",
       "   'job_highlights': [{'title': 'Qualifications',\n",
       "     'items': ['We’re looking for a person with the ability to work with a range of data and reporting technologies (eg',\n",
       "      \"Bachelor's degree in Economics, Business, Finance, Engineering, Statistics, Computer Science or related fields\",\n",
       "      '2 years of relevant work experience creating and maintaining data pipelines and architecture',\n",
       "      'Understanding of advanced data warehousing concepts, data modeling and extract, transform and load development',\n",
       "      'Advanced SQL skills with experience querying large datasets from multiple sources and developing automated reporting',\n",
       "      'Python skills for scripting, data manipulation, custom extract, transform and loads and statistical/regression analysis particularly, as they apply to sales and marketing operations and performance',\n",
       "      'Experience with software programs, such as Tableau, Microsoft Power BI, Docker, Linux and Postgres',\n",
       "      'Ability to display complex quantitative data in a simple, intuitive format and to present findings in a clear and concise manner',\n",
       "      'Capable of investigating, familiarizing and mastering new data sets quickly',\n",
       "      'Excellent interpersonal skills, with the ability to communicate complex data issues correctly and clearly to both internal and external customers',\n",
       "      'Experience with presenting actionable insights to business stakeholders']},\n",
       "    {'title': 'Responsibilities',\n",
       "     'items': ['The Data Engineer will join other Engineers and Analytics professionals as part of the team that develops data pipelines and insights for our internal stakeholders across Sales, Customer Success, Marketing, Research, Product, Finance and Administration',\n",
       "      'You’ll be PitchBook’s expert at building unified data tech to support advanced and automated business analytics',\n",
       "      'Design, develop, document and maintain database and reporting structures used to compile insights',\n",
       "      'Define, develop and review extract, transform and load processes and data modeling solutions',\n",
       "      'Consistently evolve data processes and techniques in accordance with industry best practices',\n",
       "      'Establish and help define reports and dashboards used to translate business data into insights, identify and prioritize operational improvement opportunities and measure business performance against objectives',\n",
       "      'Contribute to the ongoing improvement of quality assurance standards and procedures']},\n",
       "    {'title': 'Benefits',\n",
       "     'items': ['Comprehensive health benefits',\n",
       "      'Additional medical wellness incentives',\n",
       "      'STD, LTD, AD&D and life insurance',\n",
       "      'Paid sabbatical program after four years',\n",
       "      'Paid family and paternity leave',\n",
       "      'Annual educational stipend',\n",
       "      'Ability to apply for tuition reimbursement',\n",
       "      'CFA exam stipend',\n",
       "      'Robust training programs on industry and soft skills',\n",
       "      'Employee assistance program',\n",
       "      'Generous allotment of vacation days, sick days and volunteer days',\n",
       "      'Matching gifts program',\n",
       "      'Employee resource groups',\n",
       "      'Subsidized emergency childcare',\n",
       "      'Dependent Care FSA',\n",
       "      'Company-wide events',\n",
       "      'Employee referral bonus program',\n",
       "      'Quarterly team building events',\n",
       "      'Financial Health',\n",
       "      '401k match',\n",
       "      'Shared ownership employee stock program',\n",
       "      'Monthly transportation stipend',\n",
       "      'Please be aware the above PitchBook benefit and perk offerings are subject to corresponding plan and policy documents and may change during the course of your employment',\n",
       "      'Annual base salary: $96,600-$164,450',\n",
       "      'Target annual bonus percentage: 10%',\n",
       "      'Starting pay will be based on several factors and commensurate with qualifications & experience']}],\n",
       "   'related_links': [{'link': 'http://pitchbook.com/',\n",
       "     'text': 'pitchbook.com'},\n",
       "    {'link': 'https://www.google.com/search?gl=us&hl=en&q=Pitchbook&sa=X&ved=0ahUKEwjPrdmhqNz-AhX_mWoFHZ20DhAQmJACCNgN',\n",
       "     'text': 'See web results for Pitchbook'}],\n",
       "   'extensions': ['1 day ago',\n",
       "    'Full-time',\n",
       "    'Health insurance',\n",
       "    'Paid time off'],\n",
       "   'detected_extensions': {'posted_at': '1 day ago',\n",
       "    'schedule_type': 'Full-time'},\n",
       "   'job_id': 'eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiJCSmtXRm5xaW85VUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJTlZXNXBkR1ZrSUZOMFlYUmxjdyIsImdsIjoidXMiLCJobCI6ImVuIiwiZmMiOiJFdmNCQ3JjQlFVVnpOMnBPVVZSdmJGRkJWbGxSZDFoVWRIWTBOVXMwZDJGUVdGbFlWbkExWVRWbVRscFNTRGhZUVZsWGNGVXhhVFkyUmtzek9GVkRiMU5WWms4eVVURTFNVWw1UVRsbk5sVmxZa3hWWXpGT1dHb3pZMDFGZW1GM1FUQmhaV3czTVRWaVJqWnZNMnhmTkc5eWVrd3dabWx4UTNsRFoyOUVlRVY0T1daUFZtUnlTWHBNU1VzeWRuaE1MVFZVUmxRdE1qazNUVEpWVlRZek1IcEVRMVpyTlZoV1MyazBORUUzYjJabU5sSnhRM2h1V2tJeWRGSkpFaGRTWDNoVVdrbGZkVVJmTFhweGRITlFibVZ0Tm1kQlJSb2lRVTh0TUhKc05qaFhYM1V0U1V4bFozSTVRVlU0TnpCaE1tUmpVa3hwYzJScFp3IiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTYiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgZGlyZWN0bHkgb24gQ2FyZWVycyBBdCBQaXRjaEJvb2sgRGF0YSAtIFBpdGNoQm9vayIsImxpbmsiOiJodHRwczovL2NhcmVlcnMucGl0Y2hib29rLmNvbS9nbG9iYWwvZW4vam9iLzQwMTA2NDEwMDYvRGF0YS1FbmdpbmVlcj91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19'},\n",
       "  {'title': 'Data Engineer',\n",
       "   'company_name': 'CAIS',\n",
       "   'location': '  New York, NY   ',\n",
       "   'via': 'via Greenhouse',\n",
       "   'description': 'CAIS is a fintech firm on a mission to build the first truly open marketplace for alternative investments, where financial advisors and asset managers can engage and transact directly on a massive scale.\\u202f We are\\u202fa\\u202frapidly growing, high-energy,\\u202fand collaborative group\\u202flooking for people with great attitudes, grit,\\u202fand creative problem-solving skills.\\u202fJoin us in disrupting a... multi-trillion-dollar\\u202findustry.\\u202f\\u202f\\n\\nWe are seeking a full time Data Engineer to join our Technology team in our New York City office.\\u202fThis role will report to our SVP of Data and will be responsible for developing and maintaining the infrastructure that makes data a central part of CAIS. The Data Engineer will collaborate with analytics and product teams to improve data models that feed business intelligence tools, increase data accessibility, and foster data-driven decision making across the firm. In addition, this role will work closely with our Product Engineering and Operations Engineering teams to provide data support on greenfield work. The ideal candidate is a strong cross-functional communicator with a proven ability to solve open-ended problems in an elegant, scalable manner. They possess creativity,\\u202fflexibility,\\u202fand the drive to consistently deliver on mission critical projects with tight timelines and competing priorities.\\u202f\\n\\nResponsibilities\\u202f\\n• Develop and automate\\u202fsecure, robust, and high-performing data platform infrastructure to drive\\u202fCAIS\\u202fbusiness growth\\n• Process data\\u202fthrough to Snowflake using SQL and\\u202fcode-based\\u202fELT (and/or ETL)\\n• Analyze production workloads and develop\\u202fdata workflow strategies to\\u202foptimize\\u202fSnowflake\\u202fwarehouse\\u202fwith scale and efficiency\\u202f\\n• Support BAU operations on Snowflake, including access management, audits, and other administrative activities\\u202f\\n• Design data models for optimal storage and retrieval that represent the product entities and meet business requirements\\u202f\\n• Leverage open-source technologies and cloud solutions to build sophisticated features that help support business analytics\\u202f\\n• Build and support pipeline orchestration via Airflow\\n• Data Architecture (Snowflake preferred)\\n\\nWhat We’re Looking For\\u202f\\n• Engineering,\\u202fMathematics,\\u202for other technical\\u202fdegree(s)\\u202f\\u202f\\u202f\\n• Understanding of AWS and how to create secure infrastructure\\u202fand data pipelines\\u202f\\n• Experience with AWS solutions such as Lambda, S3,\\u202fand Kafka\\n• Experience with Athena\\n• Experience with DBT\\n• Experience with Snowflake database\\n• Experience with Integration tools like Fivetran/Airbyte\\n• 5+ years of experience with SQL\\n• Strong understanding of\\u202fa coding language to extract and transform data such as\\u202fPython/Java\\u202f\\u202f\\n• 5+ years\\u202fof data warehousing experience\\u202fwith examples of complex ETL/ELT data workflows\\u202f\\n• 5+ years of experience with schema design and dimensional data modeling\\u202f\\n• 5+ years of experience\\u202fwith\\u202fobject-oriented/functional programming, strong ability to write easy-to-scale, high-quality code\\n• Experience with or knowledge of Agile Software Development methodologies\\u202f\\n\\nDesirable Skills/Knowledge\\u202f\\n• Prior experience working within Alternative Investments and/or Financial Services preferred\\n• Good knowledge of financial markets and financial instruments\\u202fa plus\\u202f\\n• Experience with GitHub Actions\\u202fa plus\\n• Experience in developing, maintaining, and managing Tableau (or similar Business Intelligence tool) a plus\\n\\nCAIS’ compensation package includes a market competitive salary, a performance bonus, and exceptional benefits. If you are located in New York, New York, the base salary range for this role is $120,000 - $200,000. Actual compensation is influenced by a wide array of factors including but not limited to skill set, level of experience, and specific office location.\\n\\nCAIS offers a comprehensive benefits package that includes generously subsidized healthcare with 100% employer paid dental and vision insurance, an employer matched retirement plan, wellness programs, and generous PTO and parental leave. Additionally, CAIS offers a flexible, hybrid in-office model; for most roles, we do not require a minimum number of days in office per week. For more information on our benefits and career opportunities, please visit our website: https://www.caisgroup.com/careers',\n",
       "   'job_highlights': [{'title': 'Qualifications',\n",
       "     'items': ['Build and support pipeline orchestration via Airflow',\n",
       "      'Engineering, Mathematics, or other technical degree(s)',\n",
       "      'Understanding of AWS and how to create secure infrastructure and data pipelines',\n",
       "      'Experience with AWS solutions such as Lambda, S3, and Kafka',\n",
       "      'Experience with Athena',\n",
       "      'Experience with DBT',\n",
       "      'Experience with Snowflake database',\n",
       "      'Experience with Integration tools like Fivetran/Airbyte',\n",
       "      '5+ years of experience with SQL',\n",
       "      'Strong understanding of a coding language to extract and transform data such as Python/Java',\n",
       "      '5+ years of data warehousing experience with examples of complex ETL/ELT data workflows',\n",
       "      '5+ years of experience with schema design and dimensional data modeling',\n",
       "      '5+ years of experience with object-oriented/functional programming, strong ability to write easy-to-scale, high-quality code',\n",
       "      'Experience with or knowledge of Agile Software Development methodologies']},\n",
       "    {'title': 'Responsibilities',\n",
       "     'items': ['The Data Engineer will collaborate with analytics and product teams to improve data models that feed business intelligence tools, increase data accessibility, and foster data-driven decision making across the firm',\n",
       "      'In addition, this role will work closely with our Product Engineering and Operations Engineering teams to provide data support on greenfield work',\n",
       "      'Develop and automate secure, robust, and high-performing data platform infrastructure to drive CAIS business growth',\n",
       "      'Analyze production workloads and develop data workflow strategies to optimize Snowflake warehouse with scale and efficiency',\n",
       "      'Support BAU operations on Snowflake, including access management, audits, and other administrative activities',\n",
       "      'Design data models for optimal storage and retrieval that represent the product entities and meet business requirements']},\n",
       "    {'title': 'Benefits',\n",
       "     'items': ['CAIS’ compensation package includes a market competitive salary, a performance bonus, and exceptional benefits',\n",
       "      'If you are located in New York, New York, the base salary range for this role is $120,000 - $200,000',\n",
       "      'Actual compensation is influenced by a wide array of factors including but not limited to skill set, level of experience, and specific office location',\n",
       "      'CAIS offers a comprehensive benefits package that includes generously subsidized healthcare with 100% employer paid dental and vision insurance, an employer matched retirement plan, wellness programs, and generous PTO and parental leave',\n",
       "      'Additionally, CAIS offers a flexible, hybrid in-office model; for most roles, we do not require a minimum number of days in office per week']}],\n",
       "   'related_links': [{'link': 'https://www.google.com/search?gl=us&hl=en&q=CAIS&sa=X&ved=0ahUKEwjPrdmhqNz-AhX_mWoFHZ20DhAQmJACCJ8O',\n",
       "     'text': 'See web results for CAIS'}],\n",
       "   'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSusg3ICwRV6kIiB3rIBQoTQMXk-Ke5-PXehjsoQ9E&s',\n",
       "   'extensions': ['1 month ago',\n",
       "    'Full-time',\n",
       "    'No degree mentioned',\n",
       "    'Health insurance',\n",
       "    'Dental insurance',\n",
       "    'Paid time off'],\n",
       "   'detected_extensions': {'posted_at': '1 month ago',\n",
       "    'schedule_type': 'Full-time'},\n",
       "   'job_id': 'eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiJNYzR2YWplQWloSUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJTlZXNXBkR1ZrSUZOMFlYUmxjdyIsImdsIjoidXMiLCJobCI6ImVuIiwiZmMiOiJFdUlCQ3FJQlFVVnpOMnBPVW5vMlR6SlJSSFIzZUVONWNFYzVSVWRhWVdreFJtWm5jSEpUU0VkS1dHVjJiSGRvYVhSNGVWQkJOa3hyTmpKVlpXUkVSMTk0UlV4MkxWVnNiblp0VERBd1pVZE9hbU41TkU5TFVtUlJjR3RxYWpaWldrNTJTalEyV0VseWRIcGpjM0ZKUlRnd1RYTnZVaTFXUzFrMmFsVTNPVGsxYnpKbk0yRmxhbWxGVDNOUlUxOUNlVWhZVDBSalozWkNaa1ZwWW5sdmJrMWtkV05uVkVwQkVoZFNYM2hVV2tsZmRVUmZMWHB4ZEhOUWJtVnRObWRCUlJvaVFVOHRNSEpzTmtWclJYTm9ORE42TW1sRVZEVnlkMVp3ZUVaeGNHMTZSMGRWZHciLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xOCIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBHcmVlbmhvdXNlIiwibGluayI6Imh0dHBzOi8vYm9hcmRzLmdyZWVuaG91c2UuaW8vY2Fpcy9qb2JzLzY2NzgxNTAwMDI/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=='}],\n",
       " 'chips': [{'type': 'Title',\n",
       "   'param': 'job_family_1',\n",
       "   'options': [{'text': 'All'},\n",
       "    {'text': 'Data engineer', 'value': 'data engineer'},\n",
       "    {'text': 'Engineer', 'value': 'engineer'},\n",
       "    {'text': 'Senior', 'value': 'senior'},\n",
       "    {'text': 'Senior specialist', 'value': 'senior specialist'},\n",
       "    {'text': 'Analyst', 'value': 'analyst'},\n",
       "    {'text': 'Data engineering', 'value': 'data engineering'},\n",
       "    {'text': 'Software engineer', 'value': 'software engineer'},\n",
       "    {'text': 'Director', 'value': 'director'},\n",
       "    {'text': 'Manager', 'value': 'manager'},\n",
       "    {'text': 'Architect', 'value': 'architect'},\n",
       "    {'text': 'Consultant', 'value': 'consultant'},\n",
       "    {'text': 'Engineer manager', 'value': 'engineer manager'},\n",
       "    {'text': 'Engineering manager', 'value': 'engineering manager'},\n",
       "    {'text': 'Intelligence engineer', 'value': 'intelligence engineer'},\n",
       "    {'text': 'President', 'value': 'president'},\n",
       "    {'text': 'Principal engineer', 'value': 'principal engineer'},\n",
       "    {'text': 'Product engineer', 'value': 'product engineer'},\n",
       "    {'text': 'Senior manager', 'value': 'senior manager'},\n",
       "    {'text': 'Sr. consultant', 'value': 'sr. consultant'},\n",
       "    {'text': 'Technical', 'value': 'technical'}]},\n",
       "  {'type': 'Location',\n",
       "   'param': 'city',\n",
       "   'options': [{'text': 'All'},\n",
       "    {'text': 'New York, NY', 'value': 'Owg_06VPwoli_nfhBo8LyA=='},\n",
       "    {'text': 'Charlotte, NC', 'value': 'gRo4_MQfVIhk0UO_5lBGiA=='},\n",
       "    {'text': 'Chicago, IL', 'value': '7cv00DwsDogAwMAJrabgrw=='},\n",
       "    {'text': 'Austin, TX', 'value': 'LwPMoJm1RIZ61WnUS0abXQ=='},\n",
       "    {'text': 'Boston, MA', 'value': 'GzE9DS1l44mg6GIBJL98eA=='},\n",
       "    {'text': 'Dallas, TX', 'value': 'S5dFe_cZTIaPZ0f2pJvsuQ=='},\n",
       "    {'text': 'Seattle, WA', 'value': 'VTPokywQkFSa1URpRmUlEA=='},\n",
       "    {'text': 'Atlanta, GA', 'value': 'jQmTaV0E9YgLYwuZL97-Zg=='},\n",
       "    {'text': 'Jersey City, NJ', 'value': '3a-_JdJQwonZJc2iE_BJAg=='},\n",
       "    {'text': 'Washington, DC', 'value': 'W-T2Wt7Gt4kqXYjUIkVSwg=='},\n",
       "    {'text': 'Richmond, VA', 'value': '7cmZVwkRsYnFPELibT7Yvw=='},\n",
       "    {'text': 'Chantilly, VA', 'value': 'GXJnGVZBtomDrRZD_PBBQA=='},\n",
       "    {'text': 'Columbia, SC', 'value': '49ExeWml-IiW-nmz9Ago8w=='},\n",
       "    {'text': 'Houston, TX', 'value': 'AYWNSLS4QIY7BWXz3gINyg=='},\n",
       "    {'text': 'Kansas City, MO', 'value': 'l5npr173wIeiUapq5iWFVQ=='},\n",
       "    {'text': 'McLean, VA', 'value': 'O3mKsew1tonx6vqtXrpijg=='},\n",
       "    {'text': 'Miami, FL', 'value': 'EcHIDqKw2YhlT63dcfKW_w=='},\n",
       "    {'text': 'Minneapolis, MN', 'value': 'vbt3k5Azs1IH7novhMmfkw=='},\n",
       "    {'text': 'Philadelphia, PA', 'value': '60u11Ni3xonBWD6M2BT1iQ=='},\n",
       "    {'text': 'Plano, TX', 'value': 'E5XFE9ohTIYrYM2JZAOqYg=='},\n",
       "    {'text': 'San Francisco, CA', 'value': 'IQBpAG2ahYD_rXbwZxNQSg=='},\n",
       "    {'text': 'San Jose, CA', 'value': '9T_5iuTKj4B7cZ_KCoyduQ=='},\n",
       "    {'text': 'Sunnyvale, CA', 'value': 'O13QqUW2j4Ciw3zdJvuNdg=='},\n",
       "    {'text': 'Arlington, VA', 'value': 'D6ene522t4mTsPZFyG_P-A=='},\n",
       "    {'text': 'Beaverton, OR', 'value': 'Y4j4diQIlVQIvayKFc_gEA=='},\n",
       "    {'text': 'Bellevue, WA', 'value': 'QWCmo89rkFRlB9DqglTPug=='},\n",
       "    {'text': 'Bethesda, MD', 'value': 'LQIkarfLt4kNzStq93myJg=='},\n",
       "    {'text': 'Cary, NC', 'value': 'Q4tK_1S9rInhS0Ra249WRA=='},\n",
       "    {'text': 'Chesterfield, MO', 'value': '4y5BMrUq34fJJxT9LrEiWA=='},\n",
       "    {'text': 'Cincinnati, OH', 'value': '-SE43rFRQIgXk8Dki377aQ=='},\n",
       "    {'text': 'Colorado Springs, CO', 'value': 'K9LmoS5BE4cTa-j1kuuOQQ=='},\n",
       "    {'text': 'Cupertino, CA', 'value': 'q3fTG1e0j4C0eOGj4T9NOQ=='},\n",
       "    {'text': 'Florham Park, NJ', 'value': 'PTdcwbanw4lgKMsFO4iZvg=='},\n",
       "    {'text': 'Frisco, TX', 'value': 'PZQJvBo8TIai_sg1sHHTyg=='},\n",
       "    {'text': 'Hartford, CT', 'value': 'pVER8hFT5omZWX3pqEqOzA=='},\n",
       "    {'text': 'Irvine, CA', 'value': '40CRaA7d3IA5mkpgdbV6pw=='},\n",
       "    {'text': 'Los Angeles, CA', 'value': 'E9on3F3HwoD0CEYlb98v4g=='},\n",
       "    {'text': 'Madison, WI', 'value': '_xkgOm1TBoiYQUi6tfwMTg=='},\n",
       "    {'text': 'Malvern, PA', 'value': '6aWQF0XtxolkzE7xw066mw=='},\n",
       "    {'text': 'Menlo Park, CA', 'value': '_4ByEbGmj4CrifJdjpm_6w=='},\n",
       "    {'text': 'Mountain View, CA', 'value': 'iQHsW0m3j4Cbr2tGStQXfA=='},\n",
       "    {'text': 'Orlando, FL', 'value': 'd7zN_thz54iev6U8BrLDCg=='},\n",
       "    {'text': 'Raleigh, NC', 'value': '9-BRny9arImt8BGKUraQZw=='},\n",
       "    {'text': 'Reston, VA', 'value': '5WUWJkdAtomfrnGo6K_fYw=='},\n",
       "    {'text': 'Riverside, CA', 'value': 'u330f9-m3IDoCl4TBdeh9w=='},\n",
       "    {'text': 'Roanoke, VA', 'value': '_Wapak0MTYibmLDby76dJA=='},\n",
       "    {'text': 'Salt Lake City, UT', 'value': '7THRiJQ9UofKMU1IoLdTWw=='},\n",
       "    {'text': 'Smithfield, RI', 'value': 'y58zL9RA5InvqE5LuKiX1Q=='},\n",
       "    {'text': 'South San Francisco, CA', 'value': '7-z-QwV5j4BdM1bneXU6-A=='},\n",
       "    {'text': 'St. Louis, MO', 'value': '-Y7t-qm02Idb4Lsiyuo5vg=='},\n",
       "    {'text': 'Sun Prairie, WI', 'value': 'pzgI-9_3BoifQLfnXHaWyQ=='},\n",
       "    {'text': 'Tampa, FL', 'value': '4dG5s4K3wohjtJaviRNfpw=='},\n",
       "    {'text': 'Westlake, TX', 'value': 'id-DiWrRTYbCisiZ12QK4g=='}]},\n",
       "  {'type': 'Date posted',\n",
       "   'param': 'date_posted',\n",
       "   'options': [{'text': 'All'},\n",
       "    {'text': 'Past day', 'value': 'today'},\n",
       "    {'text': 'Past 3 days', 'value': '3days'},\n",
       "    {'text': 'Past week', 'value': 'week'},\n",
       "    {'text': 'Past month', 'value': 'month'}]},\n",
       "  {'type': 'Requirements',\n",
       "   'param': 'requirements',\n",
       "   'options': [{'text': 'All'},\n",
       "    {'text': 'No degree', 'value': 'no_degree'},\n",
       "    {'text': 'No experience', 'value': 'no_experience'},\n",
       "    {'text': 'Under 3 years of experience', 'value': 'years3under'},\n",
       "    {'text': '3+ years of experience', 'value': 'years3plus'}]},\n",
       "  {'type': 'Type',\n",
       "   'param': 'employment_type',\n",
       "   'options': [{'text': 'All'},\n",
       "    {'text': 'Full-time', 'value': 'FULLTIME'},\n",
       "    {'text': 'Contractor', 'value': 'CONTRACTOR'},\n",
       "    {'text': 'Part-time', 'value': 'PARTTIME'},\n",
       "    {'text': 'Internship', 'value': 'INTERN'}]},\n",
       "  {'type': 'Company type',\n",
       "   'param': 'industry.id',\n",
       "   'options': [{'text': 'All'},\n",
       "    {'text': 'Finance', 'value': '/business/naics2007/52'},\n",
       "    {'text': 'Manufacturing', 'value': '/business/naics2007/31'},\n",
       "    {'text': 'Consulting', 'value': '/business/naics2007/5416'},\n",
       "    {'text': 'Staffing', 'value': '/business/naics2007/5613'},\n",
       "    {'text': 'Health Care', 'value': '/business/naics2007/62'},\n",
       "    {'text': 'Information', 'value': '/business/naics2007/51'},\n",
       "    {'text': 'Computer Services', 'value': '/business/naics2007/5415'},\n",
       "    {'text': 'Retail', 'value': '/business/naics2007/44'},\n",
       "    {'text': 'Wholesale', 'value': '/business/naics2007/42'},\n",
       "    {'text': 'Education', 'value': '/business/naics2007/61'},\n",
       "    {'text': 'Mining', 'value': '/business/naics2007/21'},\n",
       "    {'text': 'Research', 'value': '/business/naics2007/5417'},\n",
       "    {'text': 'Logistics', 'value': '/business/naics2007/48'},\n",
       "    {'text': 'Utilities', 'value': '/business/naics2007/22'},\n",
       "    {'text': 'Accounting', 'value': '/business/naics2007/5412'},\n",
       "    {'text': 'Business Support', 'value': '/business/naics2007/5614'},\n",
       "    {'text': 'Construction', 'value': '/business/naics2007/23'},\n",
       "    {'text': 'Engineering Services', 'value': '/business/naics2007/5413'},\n",
       "    {'text': 'Entertainment', 'value': '/business/naics2007/71'},\n",
       "    {'text': 'Foods & Beverages', 'value': '/business/naics2007/311'},\n",
       "    {'text': 'Real Estate', 'value': '/business/naics2007/53'},\n",
       "    {'text': 'Rental', 'value': '/business/naics2007/532'},\n",
       "    {'text': 'Textiles & Apparel', 'value': '/business/naics2007/313'}]},\n",
       "  {'type': 'Employer',\n",
       "   'param': 'organization_mid',\n",
       "   'options': [{'text': 'All'},\n",
       "    {'text': 'Capital One', 'value': '/m/04c_q_'},\n",
       "    {'text': 'Motion Recruitment', 'value': '/g/1dtxtpd9'},\n",
       "    {'text': 'Travelers', 'value': '/m/065d4n'},\n",
       "    {'text': 'Diverse Lynx', 'value': '/g/11dxp_49r_'},\n",
       "    {'text': 'Jobot', 'value': '/g/11jrq3t_g3'},\n",
       "    {'text': 'KPMG', 'value': '/m/0k2gt'},\n",
       "    {'text': 'Barclays', 'value': '/m/05t8c5'},\n",
       "    {'text': 'Booz Allen Hamilton', 'value': '/m/05jlg3'},\n",
       "    {'text': 'Cardinal Health', 'value': '/m/040vzx'},\n",
       "    {'text': 'Deloitte', 'value': '/m/02spfd'},\n",
       "    {'text': 'Meta', 'value': '/m/0hmyfsv'},\n",
       "    {'text': 'Robert Half', 'value': '/m/07k98m'},\n",
       "    {'text': 'S&P Global', 'value': '/m/02_nl4'},\n",
       "    {'text': 'Takeda Pharmaceutical', 'value': '/m/01rm4t'},\n",
       "    {'text': 'Wells Fargo', 'value': '/m/01kdws'},\n",
       "    {'text': 'Apple', 'value': '/m/0k8z'},\n",
       "    {'text': 'Citigroup, Inc.', 'value': '/m/01dfb6'},\n",
       "    {'text': 'Compu-Vision Consulting Inc.', 'value': '/g/11dymd9t7b'},\n",
       "    {'text': 'GSK', 'value': '/m/01bbm7'},\n",
       "    {'text': 'Humana', 'value': '/m/033th4'},\n",
       "    {'text': 'SHI', 'value': '/m/0gmcsgv'},\n",
       "    {'text': 'UnitedHealth Group', 'value': '/m/060jqm'},\n",
       "    {'text': 'AXS', 'value': '/m/04sz_0'},\n",
       "    {'text': 'Accenture', 'value': '/m/01rp2c'},\n",
       "    {'text': 'Actalent', 'value': '/g/11rsrhnd_x'},\n",
       "    {'text': 'Aditi Consulting', 'value': '/m/02x0w19'},\n",
       "    {'text': 'Advanced Knowledge Tech LLC', 'value': '/g/11tcn028rz'},\n",
       "    {'text': 'Amazon', 'value': '/m/0mgkg'},\n",
       "    {'text': 'Amazon.com Services LLC', 'value': '/g/11f00sjtl5'},\n",
       "    {'text': 'Ampcus Incorporated', 'value': '/g/11fy28d4vn'},\n",
       "    {'text': 'Anheuser-Busch', 'value': '/m/01t53n'},\n",
       "    {'text': 'Arcadis', 'value': '/m/027rlqv'},\n",
       "    {'text': 'Arrow Electronics', 'value': '/m/0cm4_z'},\n",
       "    {'text': 'Axiom Global Technologies, Inc', 'value': '/g/11sfgcjww4'},\n",
       "    {'text': 'BETA Technologies', 'value': '/g/11h0092qq3'},\n",
       "    {'text': 'BNY Mellon', 'value': '/m/02vps5x'},\n",
       "    {'text': 'BP', 'value': '/m/0k5b5'},\n",
       "    {'text': 'Bayer', 'value': '/m/01snr1'},\n",
       "    {'text': 'Blue Health Intelligence', 'value': '/g/11c73j68dg'},\n",
       "    {'text': 'Boomi', 'value': '/m/03brmbq'},\n",
       "    {'text': 'Boston Consulting Group (BCG)', 'value': '/m/03w00p'},\n",
       "    {'text': 'Boston Scientific Corporation', 'value': '/m/04s6h0'}]}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "  \"api_key\": \"487a41678b75975a232403212b1c4a7b8bb45f91cbf6daa07ab0953619077d27\",\n",
    "  \"engine\": \"google_jobs\",\n",
    "  \"google_domain\": \"google.com\",\n",
    "  \"q\": \"data engineer\",\n",
    "  \"hl\": \"en\",\n",
    "  \"gl\": \"us\",\n",
    "  \"location\": \"United States\"\n",
    "}\n",
    "    \n",
    "search = GoogleSearch(params)\n",
    "results = search.get_dict()\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
